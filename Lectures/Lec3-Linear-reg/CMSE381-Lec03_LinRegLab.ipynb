{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Simple Linear Regression\n",
    "## CMSE 381 - Spring 2024\n",
    "\n",
    "\n",
    "In the today's lectures, we are focused on simple linear regression, that is, fitting models of the form \n",
    "$$\n",
    "Y =  \\beta_0 +  \\beta_1 X_1 + \\varepsilon\n",
    "$$\n",
    "In this lab, we will use two different tools for linear regression. \n",
    "- [Scikit learn](https://scikit-learn.org/stable/index.html) is arguably the most used tool for machine learning in python \n",
    "- [Statsmodels](https://www.statsmodels.org) provides many of the statisitcial tests we've been learning in class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. A note on datasets and ethics\n",
    "\n",
    "For much of this course, we will follow the labs outlined in the textbook at the end of each section (albeit, translated into python).  However, there are many portions of this book that rely on the `Boston` data set. Although this dataset has been a standard example for a long time, often used for teaching linear regression, it has some major issues with assumptions based around race and housing. An excellent in-depth description of issues in the data set can be found [in this medium post from a few years ago](https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8). More recently, the data set has [marked as deprecated in scikit-learn 1.0](https://twitter.com/ogrisel/status/1442894248488046595), which essentially means that anyone loading it will encounter a warning, and is marked for removal in version 1.2.  For these reasons, we will not be using the dataset in this class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As always, we start with our favorite standard imports. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we will be using the `Diabetes` data set.  while we could download a csv to put in the correct folder yadda yadda yadda, because this is a commonly used test data set, it's available in `scikit-learn` for us to use without any cleanup. Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data':           age       sex       bmi        bp        s1        s2        s3  \\\n",
       " 0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       " 1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       " 2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       " 3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       " 4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       " 438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       " 439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       " 440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       " 441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       " \n",
       "            s4        s5        s6  \n",
       " 0   -0.002592  0.019907 -0.017646  \n",
       " 1   -0.039493 -0.068332 -0.092204  \n",
       " 2   -0.002592  0.002861 -0.025930  \n",
       " 3    0.034309  0.022688 -0.009362  \n",
       " 4   -0.002592 -0.031988 -0.046641  \n",
       " ..        ...       ...       ...  \n",
       " 437 -0.002592  0.031193  0.007207  \n",
       " 438  0.034309 -0.018114  0.044485  \n",
       " 439 -0.011080 -0.046883  0.015491  \n",
       " 440  0.026560  0.044529 -0.025930  \n",
       " 441 -0.039493 -0.004222  0.003064  \n",
       " \n",
       " [442 rows x 10 columns],\n",
       " 'target': 0      151.0\n",
       " 1       75.0\n",
       " 2      141.0\n",
       " 3      206.0\n",
       " 4      135.0\n",
       "        ...  \n",
       " 437    178.0\n",
       " 438    104.0\n",
       " 439    132.0\n",
       " 440    220.0\n",
       " 441     57.0\n",
       " Name: target, Length: 442, dtype: float64,\n",
       " 'frame':           age       sex       bmi        bp        s1        s2        s3  \\\n",
       " 0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       " 1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       " 2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       " 3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       " 4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       " 438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       " 439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       " 440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       " 441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       " \n",
       "            s4        s5        s6  target  \n",
       " 0   -0.002592  0.019907 -0.017646   151.0  \n",
       " 1   -0.039493 -0.068332 -0.092204    75.0  \n",
       " 2   -0.002592  0.002861 -0.025930   141.0  \n",
       " 3    0.034309  0.022688 -0.009362   206.0  \n",
       " 4   -0.002592 -0.031988 -0.046641   135.0  \n",
       " ..        ...       ...       ...     ...  \n",
       " 437 -0.002592  0.031193  0.007207   178.0  \n",
       " 438  0.034309 -0.018114  0.044485   104.0  \n",
       " 439 -0.011080 -0.046883  0.015491   132.0  \n",
       " 440  0.026560  0.044529 -0.025930   220.0  \n",
       " 441 -0.039493 -0.004222  0.003064    57.0  \n",
       " \n",
       " [442 rows x 11 columns],\n",
       " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n',\n",
       " 'feature_names': ['age',\n",
       "  'sex',\n",
       "  'bmi',\n",
       "  'bp',\n",
       "  's1',\n",
       "  's2',\n",
       "  's3',\n",
       "  's4',\n",
       "  's5',\n",
       "  's6'],\n",
       " 'data_filename': 'diabetes_data_raw.csv.gz',\n",
       " 'target_filename': 'diabetes_target.csv.gz',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that this loads in a lot of info into what is essentially a beastly dictionary.\n",
    "print(type(diabetes))\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019907 -0.017646   151.0  \n",
       "1   -0.039493 -0.068332 -0.092204    75.0  \n",
       "2   -0.002592  0.002861 -0.025930   141.0  \n",
       "3    0.034309  0.022688 -0.009362   206.0  \n",
       "4   -0.002592 -0.031988 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018114  0.044485   104.0  \n",
       "439 -0.011080 -0.046883  0.015491   132.0  \n",
       "440  0.026560  0.044529 -0.025930   220.0  \n",
       "441 -0.039493 -0.004222  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But we can immediately get it into a pandas data frame for ease of use as follows \n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
    "diabetes_df['target'] = pd.Series(diabetes.target)\n",
    "\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the data set \n",
    "\n",
    "Look up the documentation about the dataset here: \n",
    "\n",
    "From https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** \n",
    "- Write a brief description of the data set. \n",
    "- What do the columns `s1` through `s6` correspond to? \n",
    "- Which of the available variables are quantitative? Which are categorical?\n",
    "- What is the `target` that we are trying to predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# 2. Getting familiar with the data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command should show you the top of your data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019907 -0.017646   151.0  \n",
       "1 -0.039493 -0.068332 -0.092204    75.0  \n",
       "2 -0.002592  0.002861 -0.025930   141.0  \n",
       "3  0.034309  0.022688 -0.009362   206.0  \n",
       "4 -0.002592 -0.031988 -0.046641   135.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** Do some basic data exploration. How many data points do we have? How many variables do we have? Are there any data points with missing data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** Use the seaborn `sns.pairplot` command to look at relationships between the variables. Are there pairs of variables that appear to be related? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "# 3. Simple Linear Regression\n",
    "\n",
    "We're now going to fig to a simple linear regression to the models\n",
    "$$\n",
    "\\texttt{target} = \\beta_0 + \\beta_1 \\cdot\\texttt{s1}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\texttt{target} = \\beta_0 + \\beta_1 \\cdot\\texttt{s5}\n",
    "$$\n",
    "where the variables are \n",
    "- $\\texttt{s1}$: tc, total serum cholesterol\n",
    "\n",
    "- $\\texttt{s5}$: ltg, possibly log of serum triglycerides level. \n",
    "\n",
    "Let's start by looking at using `s5` to predict `target`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# sklearn actually likes being handed numpy arrays more than \n",
    "# pandas dataframes, so we'll extract the bits we want and just pass it that. \n",
    "X = diabetes_df['s5'].values\n",
    "X = X.reshape([len(X),1])\n",
    "y = diabetes_df['target'].values\n",
    "y = y.reshape([len(y),1])\n",
    "\n",
    "# This code works by first creating an instance of \n",
    "# the linear regression class\n",
    "reg = LinearRegression()\n",
    "# Then we pass in the data we want it to use to fit.\n",
    "reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the fork, nothing seems to have happened? Well actually, we first created an instance of the regression class, which is just a collection of the model functionality waiting to be trained. When we run the `fit` command with data handed in, it actually figures out the best choice of coefficients for our particular data. Once they're found, we can extract them from the class as follows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can find the intercept and coefficient information \n",
    "# from the regression class as follows.\n",
    "\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** \n",
    "- What is the model using these coefficients? That is, write down the function $\\hat f$ explicitly. \n",
    "- What is the prediction by the model for $\\texttt{s5} = 0.05$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** Overlay a plot of your predicted model (your line) on a scatter plot of the data used. Does linear seem like a good assumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out there is a bit of a cheap trick for plotting linear regression using seaborn.  This command will actually both run the linear regression (that is, find the required $\\beta_i$'s) and plot it for you. The tradeoff is that this will only work for single variable linear regression; we'll have to work harder when we're doing multi-variable linear regression. They also do not provide any easy way to get the equation of the line out, so this isn't really the best tool to use for anything other than quick and dirty visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First easy version, but hard to get out the parameters....\n",
    "sns.regplot(x = diabetes_df.s5,y = diabetes_df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating data \n",
    "Ok, let's run an example like was shown in class where we see the distribution of possible values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's code that decides on my function \n",
    "def myFunc(x, b0=2, b1=5): \n",
    "    return b0 + b1*x\n",
    "\n",
    "\n",
    "# Here's a command that generates 100 random data points from f(x) + epsilon\n",
    "def makeData(n = 100):\n",
    "    X = np.random.uniform(-2,2,n)\n",
    "    y = myFunc(X) + np.random.normal(size = n)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x177116fa190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Everytime you run this cell, you get slightly different data\n",
    "\n",
    "X,y = makeData()\n",
    "\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which means that every time you run this cell, you get a slightly different choice of coefficients\n",
    "# for the model learned\n",
    "\n",
    "X,y = makeData()\n",
    "X = X.reshape([len(X),1])\n",
    "y = y.reshape([len(y),1])\n",
    "reg = LinearRegression()\n",
    "reg.fit(X,y)\n",
    "print( 'y=' + str(round(reg.coef_[0,0],4)) +  \"x_1 + \" +  str(round(reg.intercept_[0],4)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now, lets just train our linear model lots of times, and collect the resulting coefficients\n",
    "\n",
    "beta0_list = []\n",
    "beta1_list = []\n",
    "for i in range(100):\n",
    "    X,y = makeData()\n",
    "    X = X.reshape([len(X),1])\n",
    "    y = y.reshape([len(y),1])\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X,y)\n",
    "    beta1_list.append(reg.coef_[0,0])\n",
    "    beta0_list.append(reg.intercept_[0])\n",
    "\n",
    "print(beta1_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** \n",
    "Make a histogram of `beta1_list` and separately, `beta0_list`.  What do you notice about the distributions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance in estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the statistical test information, we will use the `statsmodels` package. You can take a look at the documentation here: www.statsmodels.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the code is intentially written to look\n",
    "# more like R than like python, but it still works!\n",
    "# Double check..... the coefficients here should be\n",
    "# about the same as those found by scikit-learn\n",
    "est = smf.ols('target ~ s5', diabetes_df).fit()\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** What is $SE(\\hat \\beta_0)$ and $SE(\\hat \\beta_1)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** If we instead use `s1` to predict the target, are $SE(\\hat \\beta_0)$ and $SE(\\hat \\beta_1)$ higher or lower than what you found for the `s5` prediction? Is this reasonable? Try plotting your predictions against scatter plots of the data to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b705dd0953f69dca89146ec74620019c2b04e6f11783bb64b91d387f23504961"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
