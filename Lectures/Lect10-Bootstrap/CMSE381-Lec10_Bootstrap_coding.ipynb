{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# Lec 16: Boostrap Coding Portion\n",
    "## CMSE 381 - Spring 2024\n",
    "## Feb 19, 2024\n",
    "\n",
    "In this lab, we are going to follow along with the book to generate boostrap samples. \n",
    "\n",
    "While `sklearn` does have a method called [`Bootstrap`](https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/generated/sklearn.cross_validation.Bootstrap.html), it doesn't quite do what we want in terms of the example from class.  So instead, we're going to use even simpler functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6395975",
   "metadata": {},
   "source": [
    "# 0. Generating data sets \n",
    "\n",
    "Below is some code that generates the data sets as described in Ch 5.2. Specifically, we wish to invest a fixed sum of money in two financial assets that yield returns of $X$ and $Y$, respectively, where $X$ and $Y$ are random quantities. \n",
    "\n",
    "We will invest a fraction $\\alpha$ of our money in $X$, and will invest the remaining $(1-\\alpha)$ in $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that every time you rerun this function, you will get a new random sample.\n",
    "def generatePortfolio(varX = 1, varY = 1.25,varXY = 0.5, seed = None):\n",
    "    cov = np.array(((varX, varXY), (varXY, varY)))\n",
    "\n",
    "    mean = (0,0)\n",
    "    \n",
    "    # This sets the seed if we don't want to generate a new data set each time\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # This generates our random data\n",
    "    portfolio = np.random.multivariate_normal(mean, cov, (100))\n",
    "    \n",
    "    portfolio = pd.DataFrame(portfolio, columns = ['X', 'Y'])\n",
    "    return portfolio\n",
    "\n",
    "portfolio = generatePortfolio(seed = 42)\n",
    "portfolio.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ea613",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(portfolio.X, portfolio.Y)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca45b81",
   "metadata": {},
   "source": [
    "If I want to see how much money I'd make in each case based on a fixed alpha, I can color the points by the amount of income I would get if that pair of $X$ $Y$ values occured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c567e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2 #<----- Messing with this number, changes what percentage I invest\n",
    "            #       in each company. \n",
    "\n",
    "income = portfolio.X*alpha + (1-alpha)*portfolio.Y\n",
    "\n",
    "plt.scatter(portfolio.X, portfolio.Y, c = income, cmap = 'flare')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022f29e",
   "metadata": {},
   "source": [
    "**<font color=red>Warning:</font>**  I'm following the book in that they call the second column $Y$, but we're not doing a variable prediction with this data set. We just happen to have  labeled the outputs of our two companies $X$ and $Y$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2ddf15",
   "metadata": {},
   "source": [
    "# 1. Approximate $\\hat \\alpha$ with simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e935545",
   "metadata": {},
   "source": [
    "We're assuming we're investing $\\alpha$ percent of our money in stock $X$ and $(1-\\alpha)$ percent of our money in stock $Y$. Our goal is to minimize the variance \n",
    "$$ \\mathrm{Var}(\\alpha X + (1-\\alpha)Y)$$\n",
    "\n",
    "In your homework, you will show that the variance is minimized when \n",
    "$$\n",
    "\\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55fcda",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** First, based on the parameters we used to simulate our data, determine the true value of $\\alpha$. *(Hint: You know what the answer should be from the slides, so make sure you can calculate it based on our inputs)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9421c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae39d08",
   "metadata": {},
   "source": [
    "Next, we will figure out how to approximate $\\alpha$ using the computed covariance from our particular data set. We can find the values for variance and covariance for our simulated data in pandas' covariance matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e62c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf13d63",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Edit the function `alpha_hat` below which takes in a data frame and returns the predicted $\\hat \\alpha$ using the equation above. Use your function on the entire data set to get an estimate $\\hat \\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa5262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_hat(df):\n",
    "    # Your code here #\n",
    "    pass \n",
    "\n",
    "    return 0 #<---- clearly this shouldn't always return 0\n",
    "    \n",
    "\n",
    "alpha_hat(portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd2df8",
   "metadata": {},
   "source": [
    "Now, if your `alpha_hat` code is working, the following loop will generate 1000 data sets, calculate $\\hat \\alpha$ for each, and draw a histogram of the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da195755",
   "metadata": {},
   "outputs": [],
   "source": [
    "allAlphas = [] \n",
    "for i in range (1000):\n",
    "    \n",
    "    # Resimualte a new portfolio data set. Because I'm not passing \n",
    "    # in a seed, I get a new portfolio data set every time. \n",
    "    portfolio = generatePortfolio()\n",
    "    \n",
    "    # Compute the alpha_hat and append it to my list\n",
    "    allAlphas.append(alpha_hat(portfolio))\n",
    "    \n",
    "print('Mean:', round(np.mean(allAlphas),2))\n",
    "print('StDev:', round(np.std(allAlphas),2))\n",
    "\n",
    "    \n",
    "plt.hist(allAlphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2012e0",
   "metadata": {},
   "source": [
    "# 2. Resampling data \n",
    "\n",
    "Ok, so normally we don't have access to those original parameters to figure out what $\\alpha$ actually should be, nor do we have the ability to simulate data for ourselves. So, the answer is the boostrap!\n",
    "\n",
    "First, we get our data set. **<font color=red>Note</font>**: For the rest of this exercise, I pretend that I am not allowed to simulate anything. I was just handed this data set and it's all I get to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a83fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = generatePortfolio(seed = 0)\n",
    "plt.scatter(portfolio.X, portfolio.Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8d711d",
   "metadata": {},
   "source": [
    "The main thing we need to do is to sample our data set with replacement, which we can do with the `sample` function built into the data frame. In this function, `frac=1` means that we use 100% of our data (so we end up with $n$ samples from our original $n$ data points), and `replace=True` means we get to pick points with replacement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_port = portfolio.sample(frac=1,replace=True)\n",
    "\n",
    "print('Notice that the `samp_port` dataframe has 100 rows.')\n",
    "print('Length of samp_port:', len(samp_port.index))\n",
    "\n",
    "print('\\nbut if we get rid of duplicates we have less \\nthan 100 data points represented.')\n",
    "print('Length of samp_port without duplicates:', len(set(samp_port.index)))\n",
    "samp_port.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f2903",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Repeat the following procedure 1000 times:\n",
    "- Generate a new sample of your `portfolio` data set (Note: DO NOT resimulate your portfolio data set)\n",
    "- Use your `alpha_hat` function from above to compute $\\hat \\alpha$ and keep it in your list\n",
    "\n",
    "Then, draw a histogram of the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphahats = []\n",
    "B = 1000 #<---- maybe set this to 10 or so while you're debugging\n",
    "\n",
    "for i in range(B):\n",
    "    \n",
    "    # Put your code in here\n",
    "    pass\n",
    "\n",
    "# a printout for debugging\n",
    "print(alphahats[:10])\n",
    "\n",
    "plt.hist(alphahats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa75d25",
   "metadata": {},
   "source": [
    "The last thing to do is determine the error estimate. Eqn 5.8 in the book says that we can estimate the error using \n",
    "$$\n",
    "SE_B(\\hat \\alpha) = \\sqrt{ \\frac{1}{B-1}\n",
    "\t\\sum_{r=1}^B \\left(\n",
    "\t\\hat \\alpha^{*r} - \\frac{1}{B}\\sum_{r'=1}^B \\hat \\alpha^{*r'}\n",
    "\t\\right)^2\n",
    "\t}\n",
    "    $$\n",
    "where $\\hat \\alpha^{*i}$ is the $i$th prediction (AKA the $i$th entry in your `alphahats` list up there). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b550471",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Use your `alphahats` list  to determine the standard error of $\\hat \\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a747d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98e047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/wangr/Documents/teaching/CMSE381/student/CMSE381SS24/Lectures/Lect10-Bootstrap\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
