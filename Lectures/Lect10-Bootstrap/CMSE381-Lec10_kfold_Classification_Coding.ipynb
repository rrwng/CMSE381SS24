{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# K-Fold CV for Classification\n",
    "## CMSE 381 - Spring 2024\n",
    "## Feb 19,  2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f1693",
   "metadata": {},
   "source": [
    "# 1. CV for a classification data set\n",
    "![Palmer Penguins Picture](https://allisonhorst.github.io/palmerpenguins/reference/figures/lter_penguins.png)\n",
    "\n",
    "*Artwork by @allison_horst*\n",
    "\n",
    "\n",
    "For this lab, we are going to use the <a href = \"https://allisonhorst.github.io/palmerpenguins/\">Palmer Penguins</a> data set by Allison Horst, Alison Hill, and Kristen Gorman. This data set was originally posted in R, but has helpfully been loaded as an easily readable python data set by installing the `palmerpenguins` package using `pip`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca41857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting palmerpenguins\n",
      "  Downloading palmerpenguins-0.1.4-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\wangr\\anaconda3\\lib\\site-packages (from palmerpenguins) (1.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\wangr\\anaconda3\\lib\\site-packages (from palmerpenguins) (1.24.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wangr\\anaconda3\\lib\\site-packages (from pandas->palmerpenguins) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\wangr\\anaconda3\\lib\\site-packages (from pandas->palmerpenguins) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wangr\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->palmerpenguins) (1.15.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Installing collected packages: palmerpenguins\n",
      "\n",
      "Successfully installed palmerpenguins-0.1.4\n"
     ]
    }
   ],
   "source": [
    "# You should only have to do this once:\n",
    "%pip install palmerpenguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b7e7b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "3          NaN     NaN  2007  \n",
       "4       3450.0  female  2007  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If it worked, this should load our dataset\n",
    "from palmerpenguins import load_penguins\n",
    "penguins = load_penguins()\n",
    "penguins.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f646b",
   "metadata": {},
   "source": [
    "As always, when playing with a new data set, your first job is to just get a feel for what's in the data. We're going to use this data to predict species of the penguin given the other information.\n",
    "\n",
    "&#9989; **<font color=red>Questions:</font>** \n",
    "- How many penguins are in the data set? \n",
    "- What are the input variables? \n",
    "- What are the possible values of the output variable? \n",
    "- Which are categorical varaibales? Which are quantitative? \n",
    "- Are there any lines with missing data? How is missing data represented in this data set? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b6a16f",
   "metadata": {},
   "source": [
    "*Your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ce53b",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Spoiler alert, there are penguins with missing data. Replace the `penguins` dataframe with one where you have removed all those lines. (*Hint: this should be a one line operation*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8fc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a5abd9",
   "metadata": {},
   "source": [
    "Our next favorite thing to do with any data set is to start trying to visualize relationships between the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(penguins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1aa4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Here is another nice visualization taken from the palmerpenguins github\n",
    "g = sns.lmplot(x=\"flipper_length_mm\",\n",
    "               y=\"body_mass_g\",\n",
    "               hue=\"species\",\n",
    "               height=7,\n",
    "               data=penguins,\n",
    "               palette=['#FF8C00','#159090','#A034F0'])\n",
    "g.set_xlabels('Flipper Length')\n",
    "g.set_ylabels('Body Mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb4017",
   "metadata": {},
   "source": [
    "## Step 1: Set up your arrays \n",
    "\n",
    "Ok, you have your penguins data frame.  \n",
    "- Build an array $X$ with `island` and `sex` replaced with dummy variable(s)\n",
    "- Save an array of the entries in `penguins.species` as $y$ (you can use the `name_of_series.values` command, or just make a list works too). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Feel free to make more cells, I spread this out over at least \n",
    "# 5 while I was trying to get everything up and running. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a0d4f3",
   "metadata": {},
   "source": [
    "## Step 2: Run logistic regression\n",
    "\n",
    "Ok, you have your penguins data with input variables as X and we are going to predict `penguins.species`. While `scikitlearn` cannot handle input variables that are categorical (hence why we had to put in our dummy variables ourselves), it's find with a predictor variable that is. The following code will fit a logistic regression on the whole data set. Of course, you know better than to actually do this to return your results, so in a moment we will be modifying this to get $k$-fold CV test errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866fbcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticmodel = LogisticRegression(max_iter = 1400) # Note, I needed to up the interations\n",
    "                                                   # to get rid of a convergence warning\n",
    "logisticmodel.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0335e878",
   "metadata": {},
   "source": [
    "Also here's some helpful code to remember how to get accuracy/error rates out of classification modules in `scikitlearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we can also get the error rate on the training set. \n",
    "from sklearn.metrics import accuracy_score\n",
    "yhat = logisticmodel.predict(X)\n",
    "accuracy = accuracy_score(yhat, y)\n",
    "# Note that accuracy is the percentage correct\n",
    "print('Accuracy:', accuracy)\n",
    "# so the percentage incorrect is\n",
    "print('Error:', 1-accuracy)\n",
    "\n",
    "# We can get the same info directly from the original model\n",
    "print('\\nAccuracy version 2:', logisticmodel.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e55fbc5",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Ok, your job, should you choose to accept it, is to \n",
    "- Train a model predicing `species` from all the input variables using logistic regression. \n",
    "- Use $k$-fold cross validation to determine the test error. I would recommend using something like $k=5$ to start building your code, but you can up it to $k=10$ when you want to see better results. \n",
    "- *Hint: while I was building my version, I had to set the `max_iter` for Logistic regression pretty high to get the model to converge. However, my error results were still pretty reasonable with lower `max_iter`, ignoring the massive amount of pink warning boxes. Feel free to mess around with this parameter to see how it affects your output.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f33be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f79113",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!\n",
    "Written by Dr. Liz Munch, Michigan State University\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e3338d56a43a0108f5ff8ffc1915439f9812d920a0d5bf5d66e4a60c981234a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
